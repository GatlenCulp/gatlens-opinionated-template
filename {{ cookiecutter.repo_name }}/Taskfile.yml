version: "3"

vars:
  PROJECT_NAME: "{{ cookiecutter.repo_name }}"
  PYTHON_VERSION: "{{ cookiecutter.python_version_number }}"
  PYTHON_INTERPRETER: python
  MODULE_NAME: "{{ cookiecutter.module_name }}"
  DOCS_PORT: "8000"

tasks:
  ###############################################################################
  # Dependencies & Environment
  ###############################################################################

  # {%- if cookiecutter.dependency_file != 'none' %}
  requirements:
    desc: Install Python dependencies
    cmds:
      # {%- if cookiecutter.environment_manager == 'uv' %}
      - uv sync
      # {%- elif "requirements.txt" == cookiecutter.dependency_file %}
      # {%- raw %}
      - "{{.PYTHON_INTERPRETER}} -m pip install -U pip"
      - "{{.PYTHON_INTERPRETER}} -m pip install -r requirements.txt"
      # {%- endraw %}
      # {%- elif "environment.yml" == cookiecutter.dependency_file %}
      # {%- raw %}
      - conda env update --name {{.PROJECT_NAME}} --file environment.yml --prune
      # {%- endraw %}
      # {%- elif "Pipfile" == cookiecutter.dependency_file %}
      - pipenv install
      # {%- endif %}
  # {%- endif %}

  # {%- if cookiecutter.environment_manager != 'none' %}
  create-environment:
    desc: Set up python interpreter environment
    cmds:
      # {%- if cookiecutter.environment_manager == 'conda' %}
      # {%- if cookiecutter.dependency_file != 'environment.yml' %}
      # {%- raw %}
      - conda create --name {{.PROJECT_NAME}} python={{.PYTHON_VERSION}} -y
      - 'echo ">>> New virtualenv with uv created. Activate with: source ''.venv/bin/activate''"'
      # {%- endraw %}
      # {%- else %}
      # {%- raw %}
      - conda env create --name {{.PROJECT_NAME}} -f environment.yml
      - 'echo ">>> conda env created. Activate with: conda activate {{.PROJECT_NAME}}"'
      # {%- endraw %}
      # {%- endif %}
      # {%- elif cookiecutter.environment_manager == 'virtualenv' %}
      # {%- raw %}
      - |
        if [ ! -z `which virtualenvwrapper.sh` ]; then 
          source `which virtualenvwrapper.sh`
          mkvirtualenv {{.PROJECT_NAME}} --python={{.PYTHON_INTERPRETER}}
          echo ">>> New virtualenv created. Activate with: workon {{.PROJECT_NAME}}"
        else 
          mkvirtualenv.bat {{.PROJECT_NAME}} --python={{.PYTHON_INTERPRETER}}
          echo ">>> New virtualenv created. Activate with: workon {{.PROJECT_NAME}}"
        fi
      # {%- endraw %}
      # {%- elif cookiecutter.environment_manager == 'pipenv' %}
      # {%- raw %}
      - pipenv --python {{.PYTHON_VERSION}}
      - 'echo ">>> New pipenv created. Activate with: pipenv shell"'
      # {%- endraw %}
      # {%- elif cookiecutter.environment_manager == 'uv' %}
      - uv venv
      - 'echo ">>> New virtualenv with uv created. Activate with: source ''.venv/bin/activate''"'
      # {%- endif %}
  # {%- endif %}

  ###############################################################################
  # Utilities
  ###############################################################################

  prep:
    desc: Clean up .DS_Store files
    cmds:
      - rm -f **/*/.DS_store

  welcome:
    desc: Print a Welcome screen
    cmds:
      - curl -s https://raw.githubusercontent.com/GatlenCulp/gatlens-opinionated-template/vscode-customization/welcome.txt

  ###############################################################################
  # Code Quality
  ###############################################################################

  clean:
    desc: Delete all compiled Python files
    cmds:
      - find . -type f -name "*.py[co]" -delete
      - find . -type d -name "__pycache__" -delete

  lint:
    desc: Lint using ruff
    cmds:
      # {%- raw %}
      - ruff check --config pyproject.toml {{.MODULE_NAME}}
      # {%- endraw %}

  format:
    desc: Format source code with ruff
    cmds:
      # {%- raw %}
      - ruff --config pyproject.toml {{.MODULE_NAME}}
      # {%- endraw %}

  ###############################################################################
  # Documentation
  ###############################################################################

  docs-serve:
    desc: Serve documentation locally
    dir: docs
    cmds:
      # {%- raw %}
      - mkdocs serve -a localhost:{{.DOCS_PORT}} || echo "Instance found running on {{.DOCS_PORT}}, try killing process and rerun."
      # {%- endraw %}

  docs-publish:
    desc: Build and deploy documentation to GitHub Pages
    dir: docs
    cmds:
      - mkdocs build
      - mkdocs gh-deploy --clean

  ###############################################################################
  # Testing
  ###############################################################################

  test:
    desc: Run all tests
    deps: [prep]
    cmds:
      - pytest -vvv --durations=0

  test-fastest:
    desc: Run tests with fail-fast option
    deps: [prep]
    cmds:
      - pytest -vvv -FFF

  test-continuous:
    desc: Run tests in watch mode using pytest-watcher
    deps: [prep]
    cmds:
      - ptw . --now --runner pytest --config-file pyproject.toml -vvv -FFF

  test-debug-last:
    desc: Debug last failed test with pdb
    cmds:
      - pytest --lf --pdb

  ###############################################################################
  # Data Sync
  ###############################################################################

  # {%- if not cookiecutter.dataset_storage.none %}
  sync-data-down:
    desc: Download data from storage system
    cmds:
      # {%- if cookiecutter.dataset_storage.s3 %}
      - aws s3 sync s3://{{ cookiecutter.dataset_storage.s3.bucket }}/data/ data/{% if cookiecutter.dataset_storage.s3.aws_profile != 'default' %} --profile {{ cookiecutter.dataset_storage.s3.aws_profile }}{% endif %}
      # {%- elif cookiecutter.dataset_storage.azure %}
      - az storage blob download-batch -s {{ cookiecutter.dataset_storage.azure.container }}/data/ -d data/
      # {%- elif cookiecutter.dataset_storage.gcs %}
      - gsutil -m rsync -r gs://{{ cookiecutter.dataset_storage.gcs.bucket }}/data/ data/
      # {%- endif %}

  sync-data-up:
    desc: Upload data to storage system
    cmds:
      # {%- if cookiecutter.dataset_storage.s3 %}
      - aws s3 sync data/ s3://{{ cookiecutter.dataset_storage.s3.bucket }}/data{% if cookiecutter.dataset_storage.s3.aws_profile != 'default' %} --profile {{ cookiecutter.dataset_storage.s3.aws_profile }}{% endif %}
      # {%- elif cookiecutter.dataset_storage.azure %}
      - az storage blob upload-batch -d {{ cookiecutter.dataset_storage.azure.container }}/data/ -s data/
      # {%- elif cookiecutter.dataset_storage.gcs %}
      - gsutil -m rsync -r data/ gs://{{ cookiecutter.dataset_storage.gcs.bucket }}/data/
      # {%- endif %}
  # {%- endif %}

  ###############################################################################
  # Project Tasks
  ###############################################################################

  # {%- if cookiecutter.include_code_scaffold != 'No' %}
  data:
    desc: Make dataset
    deps: [requirements]
    cmds:
      # {%- raw %}
      - "{{.PYTHON_INTERPRETER}} {{.MODULE_NAME}}/dataset.py"
      # {%- endraw %}
  # {%- endif %}

  default:
    desc: List all available tasks
    cmds:
      - task --list

  # {% if cookiecutter.use_github == 'Yes' %}
  ###############################################################################
  # Pre-commit
  ###############################################################################

  pre-commit-test:
    desc: Test hooks
    cmds:
      - pre-commit run --all-files
      - git add .pre-commit-config.yaml
      - pre-commit run commitizen --hook-stage commit-msg --commit-msg-filename ".git/COMMIT_EDITMSG"

  pre-commit-update:
    desc: Update, install, and test hooks w/ new config
    cmds:
      - pre-commit autoupdate
      - pre-commit install
      - task: pre-commit-test
  # {% endif %}
